AZURE_CHAT_DEPLOYMENT_NAME="model-router"
AZURE_AUDIO_DEPLOYMENT_NAME="gpt4o-transcribe"

AI_FOUNDRY_PROJECT_ENDPOINT="https://<name>.services.ai.azure.com/api/projects/<project-name>"

# Required: Hugging Face token for model access
HUGGING_FACE_TOKEN=your_hugging_face_token_here

# Optional: Device for ML inference (cpu, cuda, mps)
INFERENCE_DEVICE=cpu

# Optional: HTTP server configuration
HTTP_HOST=0.0.0.0
HTTP_PORT=8000

# Traces/logs/metric gRPC ingress
OTLP_ENDPOINT="http://localhost:4317"
# Semantic Kernel diagnostics settings
# Set to true to enable sensitive diagnostics data collection, only for debugging purposes
SEMANTICKERNEL_EXPERIMENTAL_GENAI_ENABLE_OTEL_DIAGNOSTICS_SENSITIVE=true