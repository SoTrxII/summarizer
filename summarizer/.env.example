
# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# Chat completion provider: "azure" or "ollama"
CHAT_COMPLETION_PROVIDER="azure"

# Azure AI Foundry Configuration (when CHAT_COMPLETION_PROVIDER="azure")
AI_FOUNDRY_PROJECT_ENDPOINT="https://<name>.services.ai.azure.com/api/projects/<project-name>"
AZURE_CHAT_DEPLOYMENT_NAME="<your_chat_deployment_name>"

# Ollama Configuration (when CHAT_COMPLETION_PROVIDER="ollama")
OLLAMA_ENDPOINT="http://localhost:11434"
OLLAMA_MODEL_NAME="phi4"

# =============================================================================
# AUDIO TRANSCRIPTION CONFIGURATION
# =============================================================================

# Audio completion provider: "azure" or "local"
AUDIO_COMPLETION_PROVIDER="local"

# Azure Audio Configuration (when AUDIO_COMPLETION_PROVIDER="azure")
AZURE_AUDIO_DEPLOYMENT_NAME="whisper"

# =============================================================================
# GENERAL CONFIGURATION
# =============================================================================

# Required: Hugging Face token for model access. 
# You must accept the conditions of the models listed here : https://github.com/m-bain/whisperX?tab=readme-ov-file#speaker-diarization
HUGGING_FACE_TOKEN=<your_hugging_face_token_here>

# Optional: Azure audio model to use. If not defined, local whisper will be used
# AZURE_AUDIO_DEPLOYMENT_NAME="gpt4o-transcribe"

# =============================================================================
# GENERAL CONFIGURATION
# =============================================================================

# Optional: Device for ML inference (cpu, cuda). If not specified, use cuda if available
INFERENCE_DEVICE=cpu

# Optional: HTTP server configuration
HTTP_HOST=0.0.0.0
HTTP_PORT=8000

# Optional: Dapr config
# Where to fetch/save audio files 
DAPR_AUDIO_STORE_NAME="audio-store"
# Where to fetch/save summary files
DAPR_SUMMARY_STORE_NAME="summary-store"

# Traces/logs/metric gRPC ingress
OTLP_ENDPOINT="http://localhost:4317"
# Semantic Kernel diagnostics settings
# Set to true to enable sensitive diagnostics data collection, only for debugging purposes
SEMANTICKERNEL_EXPERIMENTAL_GENAI_ENABLE_OTEL_DIAGNOSTICS_SENSITIVE=true

# =============================================================================
# AZURE SPECIFIC CONFIGURATION
# =============================================================================

# There are a few ways to authenticate with Azure services.
# In development, just use az login to authenticate with your Azure account.

# In production, use either a Managed Identity or a Service Principal
# See all options here: https://learn.microsoft.com/en-us/azure/developer/python/azure-sdk-authenticate#service-principal

# Example : Using a service principal
AZURE_TENANT_ID = "<your_azure_tenant_id>"
AZURE_CLIENT_ID = "<your_azure_client_id>"
AZURE_CLIENT_SECRET = "<your_azure_client_secret>"