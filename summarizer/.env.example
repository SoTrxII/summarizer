
# Required: Azure foundry llm binding
AI_FOUNDRY_PROJECT_ENDPOINT="https://<name>.services.ai.azure.com/api/projects/<project-name>"
AZURE_CHAT_DEPLOYMENT_NAME="<your_chat_deployment_name>"

# Required: Hugging Face token for model access. 
# You must accept the conditions of the models listed here : https://github.com/m-bain/whisperX?tab=readme-ov-file#speaker-diarization
HUGGING_FACE_TOKEN=<your_hugging_face_token_here>

# Optional: Azure audio model to use.If not defined, local whisper will be used
AZURE_AUDIO_DEPLOYMENT_NAME="gpt4o-transcribe"

# Optional: Device for ML inference (cpu, cuda)
INFERENCE_DEVICE=cpu

# Optional: HTTP server configuration
HTTP_HOST=0.0.0.0
HTTP_PORT=8000

# Optional: Dapr config
# Where to fetch/save audio files 
DAPR_AUDIO_STORE_NAME="audio-store"
# Where to fetch/save summary files
DAPR_SUMMARY_STORE_NAME="summary-store"

# Traces/logs/metric gRPC ingress
OTLP_ENDPOINT="http://localhost:4317"
# Semantic Kernel diagnostics settings
# Set to true to enable sensitive diagnostics data collection, only for debugging purposes
SEMANTICKERNEL_EXPERIMENTAL_GENAI_ENABLE_OTEL_DIAGNOSTICS_SENSITIVE=true